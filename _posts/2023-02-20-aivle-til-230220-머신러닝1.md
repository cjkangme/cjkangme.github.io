

        ---
        title: AIVLE TIL ('23.02.20) 머신러닝(1)
        date: 2023-02-20 14:15:52.512 +0000
        categories: [에이블스쿨]
        tags: ['aivle']
        description: 머신러닝의 원리를 배우기 앞서 일단 코드부터 짜보자
        image: /assets/img/posts/2023-02-20-aivle-til-230220-머신러닝1/thumbnail.png
        
        ---

        # 오늘 배운 것

## 머신러닝 학습의 과정

- 머신러닝, 딥러닝에서 중요한 것은 바로 코드를 짤 줄 알아야 한 다는 것
전체 시간의 80%는 데이터 분석 및 전처리, 15%는 결과분석, 머신러닝은 단 5% 정도이다.
코딩에 막혀서 모델링을 하지 못하는 것이 제일 문제

- 우선 사용하고, 그 다음에 배워야 한다 (권고)
    1. 분류와 회귀 이해
    2. 모델링 코드 무작정 익히기
    3. 평가 방법 이해
    4. 중요 알고리즘의 원리 이해

- 오늘은 1일차이고 처음 머신러닝을 접하는 만큼 코드 반복 숙달 위주로 진행

## 머신러닝의 개념

규칙 : `1 → 3`, `2 → 5`, `3 → 7`, `4 → 9`

알고 싶은 것 : `5 → ?`

여기서 규칙은 `y = 2x + 1` 이며 문제의 정답은 11임을 알 수 있다.
이렇게 주어진 학습데이터를 바탕으로 모델(규칙)을 만들어 정답을 추출하도록 하는 것이 머신 러닝이다.

실제로는 현실의 복잡한 데이터가 주어지므로 딱딱 맞아 떨어지는 답을 낼 순 없다. 대신 최대한 정답에 근접한 답을 도출하는 것을 목표로 한다.

## 학습 방법에 따른 분류

### 지도 학습 (우리가 배우는 과정)

- 문제와 정답(x와 y)가 모두 있는 데이터를 제공하여 학습시켜 데이터 패턴을 배우게 하는 학습 방법

### 비지도 학습

- 정답이 없는 데이터 만으로 배우게 하는 학습 방법
- 정답을 모르기 때문에 머신 러닝의 결과를 우리가 판단할 수 없다.

### 강화 학습

- 선택한 결과에 따라 보상치를 부여하는 것을 통해 행동을 개선하면서 배우게 하는 학습 방법

## 과제에 따른 분류(중요)

> 과제를 명확히 파악하는 것이 중요하다.
> 과제에 따라 사용하는 알고리즘, 평가방법이 모두 달라지기 때문에 잘못하면 과정 전체가 잘못된다.

### 분류 문제 (지도학습)

- 이미 적절히 분류된 데이터를 통해 분류 규칙을 학습
- 새로운 데이터가 주어졌을 때 적절히 분류하는 것이 목적 -> 명확한 정답이 있고, 정답률로 평가 가능

### 회귀 문제 (지도학습)

- 결과 값이 있는 데이터를 통해, 입력값과 결과값의 연관성을 학습
- 학습한 연관성을 바탕으로 새롭게 주어진 데이터의 결과를 예측 -> 100% 일치하는 것은 불가능하기 때문에 다양한 종류의 오차를 이용한 평가 진행

> **분류와 회귀를 구분하는 팁**
> - 두 값 사이의 중간 값이 의미가 있는가? -> 있다면 회귀 문제
    - 가입여부 0, 1의 중간값 0.5는 아무 의미가 없지만, 온도 20도, 40도 사이의 30도는 의미가 있음
> - 두 값 사이의 연산 결과가 의미가 있는가?

### 클러스터링 (비지도학습)

- 정답이 없는 주어진 데이터에서 적절한 분류 규칙을 찾아 데이터를 분류
- 성능을 평가하기 어려움

## 머신러닝을 위한 데이터 전처리

1. 모든 데이터가 숫자 자료형이어야 한다
2. 결측치가 있어선 안된다
3. 되도록 가변수화하는 것이 좋다.

### 결측치 제거

- 결측치를 처리하는 방법 중 결측치를 아예 제거하는 방법이다.
- `df.dropna()` 메서드를 사용한다.
    - `axis=0`이면 결측치가 포함된 행을, `axis=1`이면 결측치가 포함된 변수를 삭제한다.
    - `subset=` 옵션을 통해 선택된 열의 결측치만 처리할 수 있다. (다른 열에 결측치가 있어도 제거하지 않음)
    
### 결측치 채우기

결측치를 제거하지 않고, 주변값을 이용해 채우는 방법이다.
주로 `df.fillna()` 메서드를 이용한다.

- 평균값 또는 중앙값으로 채우기 : 먼저 평균값을 구해 저장한뒤 `df[column].fillna(var_mean)`으로 채운다
- 최빈값으로 채우기 : 최빈값을 구한 뒤 `df[column].fillna(최빈값)`으로 채운다.


- 앞, 뒤의 값으로 채우기 : `df.fillna(method=<채울 방법>)`으로 앞, 뒤값을 이용해 결측치를 채울 수 있다.
    - `method='ffill'` : 위쪽의 행에서 값을 가져와 결측치를 채운다.
    - `method='bfill'` : 아래쪽의 행에서 값을 가져와 결측치를 채운다.
- 선형 보간법(앞뒤값의 평균) : `df.interpolate(method='linear')`로 선형보간법으로 결측치를 채울 수 있다.
    - 그외 비선형보간법을 사용하는 옵션도 있다.
    
### 가변수화

- 판다스가 제공하는 `get_dummies` 함수를 통해 가변수화가 가능하다.
    - `data = pd.get_dummies(data, columns=<cols>, drop_first=<bool>`

- 가변수화를 하는 목적은 크게 2가지가 있다.
	1. 문자열(object) 자료형의 범주형 데이터를 숫자 자료형으로 변환
    2. `1, 2, 3, 4...` 와 같은 값을 가진 범주 데이터는 머신러닝에서 연속형 변수와 동일하게 인식되기 때문에, 가변수화를 통해 범주별로 독립된 열을 만들어 해결
    
- 가변수화는 오직 머신러닝을 위한 데이터 처리기 때문에, 데이터 분석 및 전처리를 모두 끝내고 머신러닝을 하기 직전 마지막으로 처리해주면 된다.

### 공선성, 다중공선성

- A : 0, B : 1, C : 2와 같은 범주형 변수를 가변수화 하면 다음과 같은 형태가 된다.

|인덱스|A|B|C|
|:---:|:---:|:---:|:---:|
|0|1|0|0|
|1|1|0|0|
|2|0|1|0|
|3|0|0|1|

- 여기서 A 변수의 값을 몰라도 B, C의 값을 알면 A가 1인지 0인지 유추할 수 있다.

- 즉 변수 A는 B, C에 종속되어있다고 할 수 있다.
    - 이러한 특징을 **공선성**이라 한다.
    - 여러개의 열에 의해 종속된 것을 특별히 **다중공선성**이라고 한다.

- 공선성 제거가 필수는 아니지만, 일부 알고리즘에서 제거하는 것이 성능에 유리한 경우가 있다.

- get_dummies()의 `drop_first=True` 옵션을 통해 첫번째 변수를 제거함으로써 공선성을 제거할 수 있다.

## 알아야 하는 용어 정리

### 모델

- 데이터로부터 패턴을 찾아 수학식으로 정리해 놓은 것
- 모델의 목적 : 샘플을 바탕으로 전체를 추정
    - 샘플 : 표본, 과거의 데이터
    - 전체 : 모집단, 현재 및 미래의 데이터

### 모델링

- 오차가 적은 모델을 만드는 과정

### 행과 열

머신러닝에서는 행과 열이 아니라 다음과 같이 부르자.

- 행 -> 관측치, 개체(인스턴스)
- 열 -> 변수, 특성, 속성, 필드

### 독립변수와 종속변수

- 독립변수(x) : 결과의 원인이 되는 값
엄밀히 말하면 공선성이 제거된 서로 독립인 변수여야 함
- 종속변수(y) : 원인으로 인해 나타난 결과

### 오차

- 관측값과 모델의 차이 : 이탈도(Deviance) -> 오차
- 사실 평균도 모델의 일종이며, 통계학에서 사용하는 가장 단순한 모델이다.
    - 머신러닝을 하면서 유념할 것은 적어도 평균보다는 정확한 예측을 해야한다는 것이다.
    
### 데이터 분리

- 평가용 데이터(Test Data)
    - 미래의 데이터를 의미
    - 학습을 할 때 평가용 데이터를 사용해서는 절대 안된다. (수능 공부를 내가 볼 수능 문제를 보면서 하는 것과 같다)

- 학습 데이터 (Train Data)
    - 과거의 데이터, 정답이 이미 존재하는 데이터를 의미

- 검증용 데이터 (Validation Data)
    - 실전에서 Test Data는 모델링 종료후 따로 제공되는 경우가 많기 때문에, 모델의 중간 성능평가 및 튜닝을 위해 학습 데이터에서 랜덤하게 추출한 검증용 데이터를 사용한다.
    
- 데이터 분리 : 하나의 dataframe으로 부터 학습용 데이터(x, y), 평가용 데이터(x, y)를 각각 분리해 내는 것

이번 수업 과정에서는 검증용 데이터 없이 학습-평가데이터로만 나누도록 한다.

### 과대적합 vs 과소적합

- 과대적합(Overfitting)
    - 학습 데이터에서 성능 점수가 높았는데, Test Data에서 점수가 낮은 경우
    - 과도한 학습으로 인해 실전 예측 성능이 저하된 것
    
- 과소적합(Underfitting)
    - 학습 데이터 점수보다 Test Data 점수가 더 높거나, 두 점수 모두 낮은 경우
    - 모델이 너무 단순하여 적절히 훈련되지 않은 것
    	1. 학습이 덜 이루어짐 (추가 학습 필요)
        2. 데이터가 너무 적음

## 모델링 코드 구조

크게 5단계로 나눌 수 있다.

### 1. 불러오기

- 모델링에 사용할 패키지는 import한다.
- 이번 강의에서는 Scikit-Learn(사이킷런)을 이용한다.
    - 지도/비지도 알고리즘을 제공하는 대표적인 파이썬 라이브러리
    - 오픈소스로, 비즈니스 관계없이 누구나 사용가능
    - 여러 알고리즘을 동일한 구조로 사용이 가능
    - 처음 머신러닝을 배울 때 가장 적합한 라이브러리

### 2. 선언하기

- 불러온 알고리즘 함수(클래스)를 선언한다.
- 아직 다루지는 않았으나, 클래스 선언시 인자를 전달하여 모델의 튜닝이 가능하다.

### 3.학습하기

- `model.fit(x_train, y_train)` 형태로 학습시킨다.
가장 오랜 시간이 소요되는 구간이다. (수업 단계에서는 데이터가 작기 때문에 금방 끝남)

### 4. 예측하기

- `model.predict(x_test)` 형태로 학습을 바탕으로 한 예측값을 확인한다.

### 5. 평가하기

- `학습함수(정답 데이터, 예측 데이터)` 형태로 학습의 결과를 점수로 산출하여 평가한다.

## 선형 회귀 모델의 코드 예제

```python
# 1단계 : 불러오기
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error

# 2단계 : 선언하기
model = LinearRegression()

# 3단계 : 학습하기
model.fit(x_train , y_train)

# 4단계 : 예측하기
y_pred= model.predict(x_test)

# 5단계 : 평가하기
print(mean_absolute_error(y_test, y_pred))
```

## 좋은 성능 점수를 받기 위해서는?

1. 좋은 데이터 (데이터 품질이 나쁠수록 학습을 위해 더욱 많은 데이터가 필요)
2. 좋은 전처리
3. 모델(알고리즘) 튜닝

        