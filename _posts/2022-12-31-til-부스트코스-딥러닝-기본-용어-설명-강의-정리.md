

---
title: [TIL] 부스트코스  딥러닝 기본 용어 설명 강의 정리
date: 2022-12-31 08:25:06.177 +0000
categories: [부스트코스-PreCourse]
tags: ['부스트코스', '프리코스']
description: 앞으로 약 10강에 걸쳐 가장 기본적인 딥러닝 Basic을 배울 것인데, 무엇을 배울 것인지 간략히 소개할 것구현 실력최근 딥러닝에서는 pytorch를 주로 사용기본이 되는 수학적 지식선형대수(Linear Algebra), 확률론(Probability)현재 트렌드 파악


---

## Introduction

- 앞으로 약 10강에 걸쳐 가장 기본적인 딥러닝 Basic을 배울 것인데, 무엇을 배울 것인지 간략히 소개할 것

### 좋은 deep learner 되기

1. 구현 실력
	- 최근 딥러닝에서는 pytorch를 주로 사용
2. 기본이 되는 수학적 지식
	- 선형대수(Linear Algebra), 확률론(Probability)
3. 현재 트렌드 파악 (가장 최신의 논문 및 연구)
	- 이번 강의는 기본에 대해 배우기 때문에 오래된 논문을 배우지만, 논문을 이렇게 찾고 배울 수 있다는 pointer를 제공할 것이다.
    
### 인공지능과 딥러닝 개념

- 인공지능 : 사람의 지능을 모방하는 것

- 머신러닝 : 인공지능의 한 분야로, 데이터를 기반으로 학습하는 것

- 딥 러닝 : 머신러닝에 신경망을 이용하는 것

> 인공지능 > 머신러닝 > 딥러닝 순으로 포괄하는 개념이다.

## 딥러닝의 4가지 Key Components

1. Data : 데이터
2. Model : 데이터를 통해 학습하는 모델
3. Loss function : 모델학습에서 **W** 가중치 행렬의 파라미터를 어떻게 update할 지 기준이 되는 함수
4. Algorithm : loss를 최소화할 수 있는 알고리즘

- 딥러닝 관련 새로운 논문/연구를 볼 때 이 네가지 관점으로 보면 이해를 잘 할 수 있다.

### 1. Data

- 풀어야하는 문제의 종류에 따라 달라진다.

- 이미지 데이터의 경우
	
    - Classification : 분류, 예를들어 해당 사진이 강아지인지, 고양이인지 분류해 라벨링
    - Semantic Segmentation : 이미지의 픽셀이 어떤 클래스에 속하는지 확인
    	- 고양이가 있는 사진이라면, 하늘, 풀, 고양이 등 여러 클래스 중 픽셀이 어디에 속하는지
    - Detection : 목표하는 물체의 경계선 박스를 찾는 것 (어디까지인가 물체인가)
    - Pose Estimation : 사람의 3차원 또는 2차원 스켈레톤 정보를 알아내는 것
    - Visual QnA : 이미지를 바탕으로 주어진 텍스트 질문에 대답
    	- 이 사람의 눈동자는 무슨 색인가?

### 2. Model

- 주어진 Task에서 가장 좋은 성능 가질 수 있는 적절한 모델을 선택해야한다.
- 다양한 모델들이 연구를 통해 계속 개발되는 중

### 3. Loss

- Loss는 우리가 달성하고자 하는 근사치를 나타낸다.
- Task에 따라 다양한 Loss function이 존재한다.
	
    - **왜 사용하는지 이해하는 것이 중요**
    - 일반적인 방법에서는 MSE(Mean Squared Error)를 가장 많이 사용한다. 
    	- 신경망의 출력값(`ŷ`)과 target 점(`y`)간 차이의 제곱값의 합을 말한다.
        - 분류 문제에서는 출력값과 라벨 데이터 사이의 plus entropy라 불리는 loss를 사용한다.
        - 확률 모델에서는 특정 값이 아니라 평균과 분산을 이용한다.
- Loss가 줄어든다는 것은 목표값과 가까워 진다는 것이지만, Loss가 줄어든다고 우리가 원하는 값을 항상 이룬다는 보장은 없다.

### 4. Algorithm 

- Optimization Algorithm으로, 데이터, 모델, loss의 3요소가 정해져 있을 때 loss를 목표값의 한 점으로 어떻게 줄일지를 결정하는 알고리즘이다.
- 다양한 방법론이 있고, 오히려 regulizer라는 학습이 잘 안되게 하는 방법론을 추가하기도 한다.
	- loss를 단순히 줄이는 것이 목표가 아니라, **학습하지 않은 데이터**에서도 신경망이 올바른 출력을 내도록 하는 것이 목표이기 때문

        